#import "../template.typ": parec
== Exercises

#parec[
  Some types of cameras expose the film by sliding a rectangular slit across the film. This leads to interesting effects when objects are moving in a different direction from the exposure slit (Glassner 1999; Stephenson 2007). Furthermore, most digital cameras read out pixel values from scanlines in succession over a period of a few milliseconds; this leads to rolling shutter artifacts, which have similar visual characteristics. Modify the way that time samples are generated in one or more of the camera implementations in this chapter to model such effects. Render images with moving objects that clearly show the effect of accounting for this issue.
][
  某些类型的相机通过滑动胶片来曝光胶片 穿过薄膜的矩形狭缝。这会产生有趣的效果 物体沿与曝光狭缝不同的方向移动 （格拉斯纳1999 ；斯蒂芬森2007 ）。 此外，大多数数码相机都读取 在一段时间内连续从扫描线输出像素值 毫秒；这会导致卷帘快门伪影， 相似的视觉特征。修改时间样本的方式 在本章中的一个或多个相机实现中生成 对此类效应进行建模。渲染带有清晰显示的移动物体的图像 会计处理这个问题的效果。
]

#parec[
  ②Write an application that loads images rendered by the SphericalCamera and uses texture mapping to apply them to a sphere centered at the eyepoint such that they can be viewed interactively. The user should be able to freely change the viewing direction. If the correct texture-mapping function is used for generating texture coordinates on the sphere, the image generated by the application will appear as if the viewer was at the camera's location in the scene when it was rendered, thus giving the user the ability to interactively look around the scene.
][
  编写一个应用程序来加载由 SphericalCamera 并使用纹理映射将它们应用到球体 以视点为中心，以便可以交互地查看它们。这 用户应该能够自由改变观看方向。如果 使用正确的纹理映射函数来生成纹理 球体上的坐标，应用程序生成的图像将 看起来就好像观看者位于场景中摄像机的位置一样 被渲染，从而使用户能够交互式地环顾四周 现场。
]

#parec[
  ②Focal stack rendering: A focal stack is a series of images of a fixed scene where the camera is focused at a different distance for each image. Hasinoff and Kutulakos (2011) and Jacobs et al. (2012) introduced a number of applications of focal stacks, including freeform depth of field, where the user can specify arbitrary depths that are in focus, achieving effects not possible with traditional optics. Render focal stacks with pbrt and write an interactive tool to control focus effects with them.
][
  焦点堆栈渲染：焦点堆栈是一个系列 相机聚焦在不同位置的固定场景的图像 每个图像的距离。哈西诺夫和库图拉科斯 ( 2011 ) 和雅各布斯等人。 ( 2012 ) 推出多项 焦点堆栈的应用，包括自由景深，其中 用户可以指定任意的焦点深度，从而达到不 传统光学可以实现。渲染焦点堆栈 pbrt 和 编写一个交互式工具来控制它们的焦点效果。
]

#parec[
  ③Light field camera: Ng et al. (2005) discussed the physical design and applications of a camera that captures small images of the exit pupil across the film, rather than averaging the radiance over the entire exit pupil at each pixel, as conventional cameras do. Such a camera captures a representation of the light field—the spatially and directionally varying distribution of radiance arriving at the camera sensor. By capturing the light field, a number of interesting operations are possible, including refocusing photographs after they have been taken. Read Ng et al.'s paper and implement a Camera in pbrt that captures the light field of a scene. Write a tool to allow users to interactively refocus these light fields.
][
  光场相机： Ng 等人。 （ 2005年） 讨论了捕捉图像的相机的物理设计和应用 出射光瞳穿过胶片的小图像，而不是平均 与传统相机一样，每个像素处整个出射光瞳的辐射率 做。这样的相机捕获光场的表示——空间和方向上变化的辐射分布 到达相机传感器。通过捕捉光场，许多 可以进行有趣的操作，包括在拍摄后重新对焦照片 他们已被带走。阅读 Ng 等人的论文并实施 Camera 在 pbrt 捕捉场景的光场。写一个工具来允许 用户可以交互地重新聚焦这些光场。
]

#parec[
  ③The Cameras in this chapter place the film at the center of and perpendicular to the optical axis. While this is the most common configuration of actual cameras, interesting effects can be achieved by adjusting the film's placement with respect to the lens system. For example, the plane of focus in the current implementation is always perpendicular to the optical axis; if the film plane (or the lens system) is tilted so that the film is not perpendicular to the optical axis, then the plane of focus is no longer perpendicular to the optical axis. (This can be useful for landscape photography, for example, where aligning the plane of focus with the ground plane allows greater depth of field even with larger apertures.) Alternatively, the film plane can be shifted so that it is not centered on the optical axis; this shift can be used to keep the plane of focus aligned with a very tall object, for example. Modify the PerspectiveCamera to allow one or both of these adjustments and render images showing the result. (You may find Kensler's (2021) chapter useful.)
][
  这 Camera 本章中的影片位于 中心并垂直于光轴。虽然这是 实机最常见的配置，有趣的效果可以 通过调整胶片相对于镜头系统的位置来实现。 例如，当前实现中的焦点平面始终是 垂直于光轴；如果胶片平面（或镜头系统） 倾斜以使胶片不垂直于光轴，则 焦平面不再垂直于光轴。 （这 对于风景摄影很有用，例如，在对齐 与地平面的焦平面甚至可以实现更大的景深 具有更大的光圈。）或者，可以移动胶片平面，以便 它不以光轴为中心；这个转变可以用来保持 例如，焦点平面与非常高的物体对齐。 修改 PerspectiveCamera 到 允许其中一项或两项调整并渲染显示 结果。 （你可能会发现肯斯勒的 （ 2021 ）章节有用。）
]

#parec[
  ②The clamping approach used to suppress outlier sample values in the RGBFilm and GBufferFilm is a heavy-handed solution that can cause a significant amount of energy loss in the image. (Consider, for example, pixels where the sun is directly visible—the radiance along rays in those pixels may be extremely high, though it is not a cause of spiky pixels and should not be clamped.) Implement a more principled solution to this problem such as the technique of Zirr et al. (2018). Render images with your implementation and pbrt's current approach and compare the results.
][
  用于抑制异常样本的钳位方法 中的值 RGBFilm 和 GBufferFilm 是一个 严厉的解决方案可能会导致大量的能量损失 图像。 （例如，考虑太阳直接照射的像素 可见——这些像素中沿光线的辐射亮度可能非常高， 尽管它不是尖峰像素的原因并且不应该被限制。） 对此问题实施更有原则的解决方案，例如技术 Zirr 等人。 （ 2018 ）。使用您的渲染图像 实施和 pbrt 当前的方法并比较结果。
]

#parec[
  ②Investigate the sources of noise in camera sensors and mathematical models to simulate them. Then, modify the PixelSensor class to model the effect of noise. In addition to shot noise, which depends on the number of photons reaching each pixel, you may also want to model factors like read noise and dark noise, which are independent of the number of photons. Render images that exhibit noise and show the effect of different types of it as exposure time varies.
][
  研究相机传感器中的噪声源并 数学模型来模拟它们。然后，修改 PixelSensor 类来模拟噪声的影响。除了散粒噪声之外， 取决于到达每个像素的光子数量，您可能还想 模型因素如读取噪声和暗噪声，它们独立于 光子数。渲染出现噪声的图像并显示以下效果 随着曝光时间的不同，它的类型也不同。
]

#parec[
  ②Because they are based on floating-point addition, which is not associative, the AddSplat() methods implemented in this chapter do not live up to pbrt's goal of producing deterministic output: if different threads add splats to the same pixel in a different order over multiple runs of pbrt, the final image may differ. An alternative implementation might allocate a separate buffer for each thread's splats and then sum the buffers at the end of rendering, which would be deterministic but would incur a memory cost proportional to the number of threads. Either implement that approach or come up with another one to address this issue and implement it in pbrt. Measure the memory and performance overhead of your approach as well as how often the current implementation is non-deterministic. Is the current implementation defensible?
][
  因为它们基于浮点加法， 不是结合律，则 AddSplat() 在此实施的方法 章不辜负 pbrt 产生确定性输出的目标： 如果不同的线程以不同的顺序将 splats 添加到同一像素 多次运行 pbrt ，最终图像可能会有所不同。另一种选择 实现可能会为每个线程的 splats 分配一个单独的缓冲区 然后在渲染结束时对缓冲区求和，即 确定性的，但会产生与数量成正比的内存成本 线程。要么实施该方法，要么提出另一种方法 解决这个问题并在 pbrt 。测量内存和性能 您的方法的开销以及当前实施的频率 是不确定的。目前的实施是否合理？
]

#parec[
  ③Image-based rendering is the general name for a set of techniques that use one or more images of a scene to synthesize new images from viewpoints different from the original ones. One such approach is light field rendering, where a set of images from a densely spaced set of positions is used—as described by Levoy and Hanrahan (1996) and Gortler et al. (1996). Read these two papers on light fields, and modify pbrt to directly generate light fields of scenes, without requiring that the renderer be run multiple times, once for each camera position. It will probably be necessary to write a specialized Camera, Sampler, and Film to do this. Also, write an interactive light field viewer that loads light fields generated by your implementation and that generates new views of the scene.
][
  基于图像的渲染是一组 使用场景的一张或多张图像来合成新图像的技术 从与原来不同的角度。其中一种方法是 光场渲染，其中来自密集空间的一组图像 使用位置——如Levoy 和 Hanrahan所描述 （ 1996 ）和戈特勒等人。 （ 1996 ）。 阅读这两篇关于光场的论文，并修改 pbrt 直接 生成场景的光场，无需运行渲染器 多次，每个相机位置一次。可能会是 需要专门写一篇 Camera , Sampler ， 和 Film 来做到这一点。另外，编写一个交互式光场查看器 加载由您的实现生成的光场并生成新视图 的场景。
]